run1:
1.参数:
  batch_size=32, epoch=40, decay_step=10, lr=1e-3
2.运行情况:
  内存占用为800M+
  花费时间较长(22s/epoch)
  稳定 每次都会更新最好状态
3.运行结果:
  train_acc: 0.89, test_acc: 0.87
  (原文提到35个epoch后达到90%+准确率)

run2:
1.参数: 同上 但去掉了BatchNorm层
2.运行情况: 时间为19s/epoch
3.运行结果:
  train_acc: 0.10, test_acc: 0.10 且每个epoch后都是这个数值

run3:
1.参数:
  batch_size=15, epoch=40, decay_step=20, lr=1e-3
2.运行情况:
  内存占用不到700M
  花费时间很长(38s/epoch)
3.运行结果:
  train_acc: 0.86, test_acc: 0.85

run4:
1.参数信息等见文件run4.txt
2.run1, run4对比: (分别使用CNN, ResNet18)
  一开始的准确率run4较好
  run4用时较长(总共约1h)
  最后的结果是run1好于run4
  run1更稳定 准确率一直在提升 而run4在上下波动
  但run4的最高准确率为0.89 优于run1 在程序中若用在线更新算法则会好于run1
